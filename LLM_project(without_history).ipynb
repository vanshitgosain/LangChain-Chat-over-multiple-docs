{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb pypdf langchain_community"
      ],
      "metadata": {
        "id": "ZFwqRt1Aurl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain --upgrade"
      ],
      "metadata": {
        "id": "k4p4F_Wkuror"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-openai"
      ],
      "metadata": {
        "id": "1vnRjNkAurrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.memory import ConversationBufferMemory,ConversationSummaryBufferMemory, ConversationBufferWindowMemory, ChatMessageHistory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "eXkUv-nrurt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "yhq199rWurv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "nKC2kXCcuryT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('PDFs/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "pcyvuttKur0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "                                               chunk_size=1000,\n",
        "                                               chunk_overlap=200)\n",
        "\n",
        "documents = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "r7c-yFp4ur2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "id": "UfGBKEvpvQli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "b_NsY6y6vQoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embeddings=OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "UsqtSdkJvQqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'docs/'"
      ],
      "metadata": {
        "id": "a_q0oG14vQtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "5G62hBdHvQw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "id": "I2vw5TM5vZvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 7})"
      ],
      "metadata": {
        "id": "9VUWgE_AvZy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0.6, max_tokens=500)"
      ],
      "metadata": {
        "id": "OkRB9uTAvZ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Build prompt\n",
        "template = \"\"\"You are an assistant for question-answering tasks. \\\n",
        "Use the following pieces of retrieved context to answer the question. Answer the question using every piece of relevant context available\\\n",
        "Answer in about 200-300 words. If you don't find answer in context, just say that you don't know. If two questions are asked together, answer them in different paragraphs\\\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "4_ecNEkdvfEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "k3rZ06eXvfGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "    print(textwrap.fill(llm_response['result'], 100))\n",
        "    print('\\n\\nSources:')\n",
        "\n",
        "    # Keep track of already printed sources and page numbers\n",
        "    printed_sources = set()\n",
        "    printed_pages = set()\n",
        "\n",
        "    for doc in llm_response['source_documents']:\n",
        "        source = doc.metadata['source']\n",
        "        page = doc.metadata['page']\n",
        "\n",
        "        # Check if source and page have not been printed before\n",
        "        if source not in printed_sources or page not in printed_pages:\n",
        "            print(\"pdf name:\", source, \"page no:\", page)\n",
        "            # Add source and page to printed sets\n",
        "            printed_sources.add(source)\n",
        "            printed_pages.add(page)"
      ],
      "metadata": {
        "id": "dbb41SzSvfIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"what does traditional growth strategies focuses on?\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "s4XFMWZmvfLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"what does traditional growth strategies focuses on in terms of economics. Also explain how inceptionNet is better than other models\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "j9AHV6qxvfNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"How does shortcut connection addresses the problem of degradation as networks are made deeper\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "BhkqGqF8vo0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"differenciate between MobileNet and InceptionV3 model?\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "wMa2P1KNvo25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"differenciate between MobileNet and InceptionV3 and residual nets model?\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "e9Mld9Znvo5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"explain the architecture of residual nets\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "qDEhs4WOvo72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"How does MobileNetV2 improves the state of the art performance of mobile models\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "m-ZQUPNjvo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"Summarize the artchitecture of Mobilenetv2 and inception V2\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "TV7l3KaQvxa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \" what are the ways of factorizing convolutions in various settings?\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "BPRwCdv0vxdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \" Who is Virat Kohli?\"})\n",
        "process_llm_response(result)"
      ],
      "metadata": {
        "id": "IFs3w7liv3Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8XPjCzFsv3fY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}