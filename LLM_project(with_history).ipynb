{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cts_ba4S9tTB"
      },
      "outputs": [],
      "source": [
        "pip install chromadb pypdf langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain --upgrade"
      ],
      "metadata": {
        "id": "kDZZCLHn9w5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-openai"
      ],
      "metadata": {
        "id": "fAJtWuTPp_DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.memory import ConversationBufferMemory,ConversationSummaryBufferMemory, ConversationBufferWindowMemory, ChatMessageHistory\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "V1l7DAyWp_KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "uXx0JmYG906R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "anP1HLq091AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('PDFs/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "k3kSQwWX91DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "                                               chunk_size=1000,\n",
        "                                               chunk_overlap=200)\n",
        "\n",
        "documents = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "MSjXKDsD91FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "id": "2KyAXxqk91HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "mkX_nDHJ91Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embeddings=OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "6eGNC5TM91L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'docs/'"
      ],
      "metadata": {
        "id": "3QNIFYNM91OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "zoZM1f0r91Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "id": "CsN9O7iC-Q4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "Xnk9O_yI-Q9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"what does traditional growth strategies focuses on\")"
      ],
      "metadata": {
        "id": "wFPKKE3A-RAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "4R9sY2SB-RGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0.6, max_tokens=100)"
      ],
      "metadata": {
        "id": "ELjwawPv-bKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "### Contextualize question ###\n",
        "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
        "which might reference context in the chat history, formulate a standalone question \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "5c9wrLMu-bND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Answer question ###\n",
        "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
        "Use the following pieces of retrieved context to answer the question. Answer the question using every piece of relevant context available\\\n",
        "Answer in about 200-300 words. If you don't find answer in context, just say that you don't know. If two questions are asked together, answer them in different paragraphs\\\n",
        "\n",
        "{context}\"\"\"\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "L9eRkcr0-bPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "### Statefully manage chat history ###\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "C1UqlSpa-bSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "\n",
        "    print(textwrap.fill(llm_response['answer'], 100))\n",
        "    print('\\n\\nSources:')\n",
        "\n",
        "    # Keep track of already printed sources and page numbers\n",
        "    printed_sources = set()\n",
        "    printed_pages = set()\n",
        "\n",
        "    for doc in llm_response['context']:\n",
        "        source = doc.metadata['source']\n",
        "        page = doc.metadata['page']\n",
        "\n",
        "        # Check if source and page have not been printed before\n",
        "        if source not in printed_sources or page not in printed_pages:\n",
        "            print(\"pdf name:\", source, \"page no:\", page)\n",
        "            # Add source and page to printed sets\n",
        "            printed_sources.add(source)\n",
        "            printed_pages.add(page)"
      ],
      "metadata": {
        "id": "sFRhHPIx-bW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"what does traditional growth strategies focuses on?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"abc123\"}\n",
        "    },  # constructs a key \"abc123\" in `store`.\n",
        ")\n",
        "\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "Hi914wDh-bUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pboD_bSUrSLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usrQ89pXrSUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8eMa4MRrSYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KKUOMidxrSde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEkavuoBrSgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mz0N2S3wrSi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHe3L4sLrSly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}